[
    {
        "id": 0,
        "title": "基于QwenLawyer-0.5B的SFT小小法律模型",
        "date": "2025-1-20",
        "author": "Busheng Zhang",
        "content": "## 0. 项目介绍\n\n寒假一直忙着在学习huggingface，没有更新我的推文，这不正好有时间用一个简单的方式做一次大模型的有监督微调(Supervised Fine-tuning，SFT)。\n\n## 1. 项目背景\n\n为什么说微调很重要呢？大模型微调的背景在于深度学习领域的发展。随着计算能力的提升和数据量的激增，大型预训练模型如BERT、GPT等在自然语言处理、计算机视觉等任务上取得了显著成果。然而，这些通用模型在特定领域或任务上可能表现不佳。为了提高模型在特定场景下的性能，研究者们开始探索微调技术。微调通过在预训练模型的基础上，利用少量特定任务的数据进行进一步训练，使模型更好地适应特定需求。这种方法既保留了预训练模型的海量知识，又增强了模型在特定领域的专精能力，从而在各类应用中展现出更高的准确性和效率。微调技术已成为深度学习领域的重要研究方向，推动着人工智能技术的广泛应用和持续创新。\n\n当然，还有一个原因是微调需要的算力少，成本低一些，微调是基于已有模型的改动，而不要从零开始训练，所以就很高效。\n\n## 2. 知识介绍：有监督微调原理（SFT）\n\n有监督微调的数学原理主要基于梯度下降和反向传播算法。首先，预训练模型在大量数据上学习到了通用的特征表示。在进行有监督微调时，模型在这些通用特征的基础上，通过特定任务的数据进行进一步学习。\n\n具体来说，假设我们有一个预训练模型$f$，其参数为$\\theta$。对于特定任务，我们有一组标注数据$(x_i, y_i)$，其中$x_i$是输入，$y_i$是对应的标签。微调的目标是找到新的参数 $\\theta'$，使得模型在特定任务上的损失函数 $L$ 最小。\n损失函数 $L$ 通常衡量模型预测 $f(x_i; \\theta)$ 和真实标签 $y_i$ 之间的差异，例如交叉熵损失。微调过程通过梯度下降算法更新参数 $\\theta$：\n\n$$\n \\theta' = \\theta - \\alpha \\nabla_{\\theta} L(f(x_i; \\theta), y_i) \n$$\n\n其中，$\\alpha$ 是学习率，\\\\\\nabla_{\\theta} L 是损失函数关于参数 $\\theta$ 的梯度。通过反向传播算法计算梯度，然后更新参数，使模型逐渐适应特定任务的数据分布，从而提高我们模型在特定任务上的性能。\n\n（所以说，机器学习的核心真的就是围绕着梯度下降算法创建各种各样的架构做出来的，真是博大精深）\n\n## 3. 项目流程\n\n首先，我的能力有限，我并不会完全手写SFT代码，这个手搓起来非常有难度，我直接使用了huggingface的`SFTTrainer`[这里也有链接，需要科学上网](https://huggingface.co/docs/trl/main/en/sft_trainer)，huggingface的库真的是非常强大，我一直用这个来对大模型进行一步一步的实验。\n\n### 3.1 数据准备\n\n我要调的是法律行业的大模型，所以我从huggingface的`datasets`库中找到了一个法律行业的问答数据集，叫做[lawyer_llama_data](https://huggingface.co/datasets/Skepsun/lawyer_llama_data)\n\n`lawyer_llama_data`是一个专门用于文本生成的中文法律数据集，适用于法律领域的自然语言处理任务。该数据集包含2.15万行训练数据，采用JSON格式存储，主要涉及中国法律文本。其任务类型为文本生成，支持多种库如Datasets和pandas进行数据处理。数据集在Apache License 2.0许可下发布，确保了使用的灵活性和广泛性。该数据集旨在通过大规模法律语料的预训练和指令微调，提升模型在法律知识理解和应用方面的能力，特别适用于训练如Lawyer LLaMA这样的法律领域大语言模型。通过这种训练，模型能够更好地进行法律条文分析、法律问答等任务，为法律实务提供智能支持。\n\n**数据格式**\n刚刚提到，这个数据是一个json格式的数据，它的features长这样：\n\n```text\nDatasetDict({\n    train: Dataset({\n        features: ['input', 'instruction', 'output', 'history', 'source', 'prefix', 'lang'],\n        num_rows: 21476\n    })\n})\n```\n\n这个拥有21476条数据的大家，咱稍微瞥一眼：\n![数据集示例](img/截屏2025-10-23 22.32.03.png)\n里面摘取几个示例：\n\n```text\n- output:根据《民事诉讼法》规定：\"当事人起诉或者答辩时，应当向人民法院提供明确的送达地址。\"这一规定直接规定了当事人起诉或答辩时需要提供明确的送达地址，属于《民事诉讼法》直接规定的内容。 另外，根据《民事诉讼法》第一百零八条规定：\"简易程序适用于争议金额不超过五万元人民币的案件，以及其他符合本法规定的案件。\"因此，当事人起诉或答辩时要向法院提供明确的送达地址，不仅是《民事诉讼法》直接规定的内容，也具有简易程序特点。 综上所述，选项\"原告起诉或被告答辩时要向法院提供明确的送达地址\"属于《民事诉讼法》直接规定、具有简易程序特点的内容。\n- instruction:下列选项属于《民事诉讼法》直接规定、具有简易程序特点的内容? 原告起诉或被告答辩时要向法院提供明确的送达地址 请给出详细的推理过程之后再给出答案。\n```\n\n### 3.2 数据预处理\n\n我的云服务器没法科学上网，我就事先下载好存到本地，我使用的huggingface镜像站点下载的，具体网址以及如何下载请看[链接](https://hf-mirror.com/)，我用这个工具下载了这样一个数据集，存在了我的`./data`文件夹下。\n\n`SFTTrainer`需要输入和输出标签，所以我对数据进行了如下处理：\n\n```python\ndef preprocess_function(examples): \n\\tinputs = [] \n\\tlabels = [] \n\\tfor instruction, output in zip(examples[\"instruction\"], examples[\"output\"]): \n\\t\\t# 构建输入序列 \n\\t\\tinput_text = f\"指令: {instruction}\\n分析结果: \"  \n\\t\\tinputs.append(input_text) \n\\t\\t\n\\t\\t# 构建标签序列 \n\\t\\tlabel_text = input_text + output labels.append(label_text) \n\\t\\t\n\\t# 对输入和标签进行分词 \n\\tmodel_inputs = tokenizer(inputs, max_length=512, truncation=True) \n\\tlabels = tokenizer(labels, max_length=512, truncation=True)\n\\tmodel_inputs[\"labels\"] = labels[\"input_ids\"] \n\\treturn model_inputs\n\ntokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n```\n\n使得最终的数据呈现出以下的形式：\n\n```text\nDataset({\n\\tinput_ids:...\n\\tattention_mask:...\n\\tlabels:...\n})\n```\n\n这个 `Dataset` 对象可以被 `SFTTrainer` 使用，`SFTTrainer` 内部会利用 `DataCollatorForLanguageModeling`（在代码中定义为 `data_collator`）对数据进行批处理。数据收集器会将多个样本组合成一个批次（batch），确保批次内所有样本的 `input_ids`、`attention_mask` 和 `labels` 具有相同的长度（通过填充和截断实现），以满足模型训练时对张量形状一致性的要求。例如，一批数据可能是形状为 `(batch_size, max_length)` 的 `input_ids` 张量、同样形状的 `attention_mask` 张量以及 `labels` 张量。\n\n```python\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n```\n\n### 3.3 训练配置\n\n这个地方我以后可以深入研究，我的配置都是使用默认配置：\n\n```python\n# 加上LoRa吧~\npeft_config = LoraConfig(\n\\tr=8,\n\\tlora_alpha=16,\n\\ttarget_modules=[\"q_proj\", \"v_proj\"],\n\\tlora_dropout=0.1,\n\\tbias=\"none\",\n\\ttask_type=\"CAUSAL_LM\"\n)\ntraining_args = {\n\\t\"output_dir\": \"./models\",\n\\t\"per_device_train_batch_size\": 4,\n\\t\"gradient_accumulation_steps\": 4,\n\\t\"learning_rate\": 2e-4,\n\\t\"num_train_epochs\": 3,\n\\t\"save_steps\": 10_000,\n\\t\"save_total_limit\": 2,\n\\t\"logging_steps\": 10,\n\\t\"fp16\": True\n}\n```\n\n然而事实上我的参数调节可以优化，(但是算了，老子只有这么多次训练机会)\n\n### 3.4 训练和保存\n\n```python\ntrainer = SFTTrainer(\n\\tmodel=model,\n\\ttrain_dataset=tokenized_train_dataset,\n\\tpeft_config=peft_config,\n\\ttokenizer=tokenizer,\n\\targs=training_args\n)\ntrainer.train()\nsave_directory = \"./models/saved_model\"\ntrainer.save_model(save_directory)\n```\n\n看一眼输出（![训练输出结果](img/截屏2025-10-23 19.54.24.png)\n因为我用的单卡V100小算力，而且模型的参数量只有0.5B（5亿参数，非常迷你），所以只用了130min(2h10min)，成本大约是10块钱左右。\n\n我的训练过程实际上可以优化，具体可以看后续的反思。\n\n### 3.5 测试模型\n\n模型训练完成啦！接下来我就开箱测试一下训练的模型吧：\n以上海迪士尼的规章制度为例：\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodelft_ckpt = './models/saved_model'\nmodel = AutoModelForCausalLM.from_pretrained(model_ckpt)\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n\ninstruction = \"上海迪士尼安检人员不准游客携带零食进入迪士尼。\"\ninput_text = f\"指令：{instruction}分析结果\\n\"\ninput_ids = tokenizer(input_text,return_tensors = \"pt\").input_ids.to(model.device)\n\n# 生成输出 \noutputs = model.generate(   input_ids, max_new_tokens=512, # 生成的最大新令牌数 \n\\t\\t\\t\\t\\tdo_sample=True, \n\\t\\t\\t\\t\\ttop_p=0.85, \n\\t\\t\\t\\t\\ttemperature=0.35 ) # 解码输出 \noutput_text = tokenizer.decode(outputs[0], skip_special_tokens=True) \n\n# 提取分析结果部分 \nresult_start_index = output_text.find(\"分析结果: \") + len(\"分析结果: \") \nfinal_result = output_text[result_start_index:] \nprint(\"分析结果:\", final_result)\n```\n\n```text\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n\n分析结果: 以下说法正确吗？ 上海迪士尼的工作人员应该具备相应的专业知识 请给出详细的推理过程之后再给出答案。 分析结果如下: 以上说法是正确的。 分析结果给出的分析过程如下: 首先，我们需要明确题目的背景信息和问题核心。题目描述了上海迪士尼乐园内存在一些不合规的行为，包括安检人员在安检过程中开启游客的行李箱，并且声称\"不允许携带食品进入\"。这些行为可能违反了相关法律法规，如《中华人民共和国食品安全法》等规定。 基于上述分析过程，我们可以得出结论：上海迪士尼的工作人员确实应该具备相关的专业知识来应对此类情况，以确保游客的安全和权益得到保障。因此，该说法是正确的。 综上所述，经过详细推理过程得出的答案是：上海迪士尼的工作人员应该具备相应的专业知识。\n```\n\n虽然我不懂法，但是看上去结果还...彳亍？毕竟只是一个0.5B的迷你模型，承载不了那么多法律条款，性能已经足够好了，感觉这个机器人还是有点哈的。\n\n## 4. 不足和反思\n\n后来大致回顾了一下整个项目的流程，还是有很多做得不足的地方：\n\n#### 数据选取\n\n实际上我后来才发现，这个数据实际上是针对法学考试的，法学考试的题目涉及的比较多。所以针对更通用的法律应用场景效果并不是完美，模型的输出更多像是回答一个考试题的样子的。而且在数据输入之前我并没有对数据进行清理，删除不良数据，这一点是下一次的微调值得改进的。\n\n#### 模型训练\n\n实际上这个模型的训练是有微小的过拟合的，训练一共有4026个epoch，在大约900多个epoch的时候误差基本上稳定在了2.4-2.7之间了，所以后续的3/4训练过程很有可能对模型造成过拟合的影响。我在下次训练的时候可以加入earlystopping机制，而且也需要使用测试集实时监控模型的误差，这样才能防止模型过拟合。\n\n好啦，以上就是寒假的时候第一次尝试的SFT微调LLM总览，代码也开源在[这里](https://github.com/gdshjzm/QWLawyer-Supervised-Fine-tuning-SFT-for-Legal-Domain-Large-Models)啦，若有哪些地方可以改进也欢迎各位大佬多提提建议！\n"
    },
    {
        "id": 1,
        "title": "基于bigcode_harness框架微调和测试模型",
        "date": "2025-03-27",
        "author": "Busheng Zhang",
        "content": "## 0. bigcode harness 框架\n\nBigCode Harness（全称 bigcode-evaluation-harness）是由 Hugging Face BigCode 项目推出的代码生成模型评估框架，它的设计灵感源自 EleutherAI 的 LM-Evaluation-Harness，但专门针对代码生成场景做了深度优化。这个框架就像一个标准化的 \"考试系统\"，能让不同的代码大模型在统一的基准下公平竞技。\n\n在接触这个框架之前，我们实验室评估模型时经常面临 \"各说各话\" 的困境 —— 不同任务需要适配不同的评测脚本，结果难以横向对比，而且代码执行安全问题也让人头疼。而 BigCode Harness 完美解决了这些痛点：它通过统一接口封装了数十种代码评估任务，支持多 GPU 并行加速，还能用 Docker 容器隔离代码执行环境，既保证了效率又兼顾了安全性。\n\n框架的核心优势体现在三个方面：首先是**任务覆盖的全面性**，包含 Python 代码生成（HumanEval、MBPP 等经典数据集）、18 种编程语言的跨语言评估（MultiPL-E）、代码鲁棒性测试（Recode）甚至编程效率评估（Mercury）等多元化任务；其次是**工程实现的先进性**，基于 Accelerate 库实现多 GPU 分布式评估，比单卡测试效率提升数倍；最后是**结果的可复现性**，通过 Docker 镜像固化依赖环境，彻底解决 \"我这能跑\" 的行业痛点。\n\n## 1. 环境搭建与安装\n\n框架的安装过程比想象中简单，官方提供了 PyPI 包和源码两种安装方式。考虑到我们需要进行微调实验，选择了从源码安装以获得更好的可定制性。\n\n首先创建 conda 环境并安装基础依赖：\n\n```bash\nconda create -n bigcode python=3.9\nconda activate bigcode\npip install torch accelerate transformers\n```\n\n然后克隆仓库并安装框架：\n\n```bash\ngit clone https://github.com/bigcode-project/bigcode-evaluation-harness.git\ncd bigcode-evaluation-harness\npip install -e .\n```\n\n对于多 GPU 配置，需要通过 Accelerate 初始化分布式环境：\n\n```bash\naccelerate config\n```\n\n这个步骤会生成配置文件，指定 GPU 数量、混合精度等参数。我们实验室的服务器有 4 张 A100，配置完成后框架会自动实现负载均衡，这比我们之前手动编写分布式代码要方便得多。\n\n特别需要注意的是代码执行权限的配置。由于评估过程中需要运行生成的代码（如单元测试），框架提供了`--allow-code-execution` flag，但默认会限制危险操作。如果是在隔离环境中测试，也可以使用官方提供的 Docker 镜像跳过本地环境配置：\n\n```bash\ndocker pull ghcr.io/bigcode-project/evaluation-harness-multiple:latest\ndocker run -it --gpus all [镜像ID] bash\n```\n\n这个 16.6GB 的镜像包含了所有预配置的依赖，对于快速复现实验非常有用，但是我自己懒得安Docker就算了，这里仅作简单介绍。\n\n## 2. 模型微调实践\n\n虽然 BigCode Harness 主要用于评估，但它可以完美衔接 SFT（监督微调）工作流。我们以实验室常用的 CodeLlama-7B 模型为例，基于 MFTCoder 框架完成微调后，直接接入 Harness 进行评估。\n\n微调数据我们混合了 HumanEval + 和 MBPP + 的任务数据，这两个数据集在 Harness 中都有对应的评估任务，能形成闭环验证。微调过程使用 LoRA 技术节省显存：\n\n```python\n# 简化的微调配置示例\nfrom mftcoder import MFTConfig, train\n\nconfig = MFTConfig(\n    model_name_or_path=\"codellama/CodeLlama-7b-hf\",\n    task_type=\"sft\",\n    lora_r=16,\n    per_device_train_batch_size=4,\n    num_train_epochs=3,\n    dataset_names=[\"humaneval+\", \"mbpp+\"]\n)\n\ntrain(config)\n```\n\n这里要注意微调参数与评估参数的一致性，比如 max_new_tokens 需要匹配下游任务要求。\n\n微调完成后，我们将模型保存到 Hugging Face Hub 格式，确保包含 tokenizer 配置，这是框架能正确加载模型的关键。\n\n## 3. 评估流程与核心参数\n\nHarness 的评估通过命令行工具`bigcode-eval`实现，一个完整的评估命令包含模型配置、任务选择和生成参数三大部分。以测试 HumanEval 任务为例：\n\n```bash\naccelerate launch main.py \\\n  --model my-finetuned-codellama \\\n  --tasks humaneval \\\n  --max_length_generation 512 \\\n  --temperature 0.2 \\\n  --n_samples 10 \\\n  --batch_size 4 \\\n  --precision fp16 \\\n  --allow_code_execution \\\n  --save_generations \\\n  --output_dir ./evaluation_results\n```\n\n这个命令背后发生了一系列复杂操作：框架首先加载指定模型和 tokenizer，然后对 HumanEval 的 164 个 Python 问题生成 10 组答案（n_samples=10），每组答案通过单元测试验证正确性，最后计算 pass@1 到 pass@10 的指标。\n\n核心参数需要根据任务特性调整：\n\n- **temperature**：代码生成推荐 0.1-0.3 的低值，保证结果确定性\n- **n_samples**：pass@k 指标需要足够样本量，通常设置 10-20\n- **precision**：FP16 足够满足精度需求，比 FP32 节省一半显存\n- **load_in_4bit**：对于 30B 以上大模型，4 位量化是必要的显存优化\n\n我们发现一个有趣现象：用 bitsandbytes 进行 4 位量化时，部分模型（如 Mistral-7B）的评估结果反而比 FP16 更高，这可能与量化过程中的伪随机特性有关。因此在对比实验中，我们始终保持量化方式的一致性。\n\n## 4. 结果分析与可视化\n\n评估完成后，框架会在 output_dir 生成 JSON 格式的结果文件，包含每个任务的详细指标。\n\n```json\n{\n  \"humaneval\": {\n    \"pass@1\": 0.3251219512195122,\n    \"pass@10\": 0.39796654620671124,\n    \"pass@100\": 0.45121951219512196\n  },\n  \"config\": {\n    \"prefix\": \"\",\n    \"do_sample\": true,\n    \"temperature\": 0.1,\n    \"top_k\": 0,\n    \"top_p\": 0.95,\n    \"n_samples\": 100,\n    \"eos\": \"<|endoftext|>\",\n    \"seed\": 0,\n    \"model\": \"/home/zbs/DeepseekCoder/LLM_cache/1.3b-base\",\n    \"modeltype\": \"causal\",\n    \"peft_model\": null,\n    \"revision\": null,\n    \"use_auth_token\": true,\n    \"trust_remote_code\": false,\n    \"tasks\": \"humaneval\",\n    \"instruction_tokens\": null,\n    \"batch_size\": 10,\n    \"max_length_generation\": 512,\n    \"precision\": \"fp32\",\n    \"load_in_8bit\": false,\n    \"load_in_4bit\": false,\n    \"left_padding\": false,\n    \"limit\": null,\n    \"limit_start\": 0,\n    \"save_every_k_tasks\": -1,\n    \"postprocess\": true,\n    \"allow_code_execution\": true,\n    \"generation_only\": false,\n    \"load_generations_path\": null,\n    \"load_data_path\": null,\n    \"metric_output_path\": \"evaluation_humaneval_base.json\",\n    \"save_generations\": true,\n    \"load_generations_intermediate_paths\": null,\n    \"save_generations_path\": \"generations.json\",\n    \"save_references\": false,\n    \"save_references_path\": \"references.json\",\n    \"prompt\": \"prompt\",\n    \"max_memory_per_gpu\": null,\n    \"check_references\": false,\n    \"use_checkpoint\": false\n  }\n}\n```\n\n在我们的实验中，微调后的 DeepseekCoder-7B 在 HumanEval 上的 pass@1 只有到 32%，比基线模型提升了 12.7%，在 MBPP 任务上也有类似幅度的提升。这印证了多任务微调策略的有效性 —— 通过在相似分布的任务上训练，模型能更好地理解代码生成的约束条件。\n\n在此基础上我们还测了其他一系列的模型：\n\n|数据集 |HumanEval |HumanEval |HumanEval |mbpp |mbpp |mbpp |\n|---|---|---|---|---|---|---|\n|指标 |pass@1 |pass@10 |pass@100 |pass@1 |pass@10 |pass@100 |\n|StarCoderBase-1B |15.8 |18.7 |20.7 |21.8 |28.3 |33.8 |\n|StarCoderBase-1B-SFT |17.8 |21.0 |23.2 |23.9 |29.7 |32.4 |\n|StarCoderBase |29.9 |41.0 |48.2 |37.9 |46.0 |52.2 |\n|StarCoderBase-SFT |37.4 |44.1 |45.7 |40.9 |46.9 |51.0 |\n|StarCoderBase-7B |— |— |— |— |— |— |\n|StarCoderBase-7B-sft |28.7 |39.8 |42.6 |36.1 |42.9 |47.0 |\n|StarCoderBase-7B【图】 |— |— |— |— |— |— |\n|DeepseekCoder-1.3B |32.5 |39.7 |45.1 |43.3 |51.2 |56.2 |\n|DeepseekCoder-1.3B-SFT |34.2 |42.6 |46.9 |44.0 |52.1 |56.0 |\n|Qwen2.5-Coder-1.5B |44.7 |55.3 |59.1 |52.7 |62.4 |67.4 |\n|Qwen2.5-Coder-1.5B-SFT |39.5 |55.7 |64.0 |52.7 |67.2 |73.2 |\n|Qwen2.5-Coder-7B-Instruct |18.9 |24.0 |25.0 |67.3 |75.2 |78.6 |\n|Qwen2.5-Coder-7B-Instruct-SFT |28.7 |39.8 |42.6 |66.8 |76.1 |79.8 |\n|Qwen2.5-Coder-7B-Instruct【图】 |— |— |— |— |— |— |\n|Qwen2.5-Coder-14B |60.2 |70.7 |— |67.3 |75.8 |— |\n|Qwen2.5-Coder-14B-SFT |61.0 |70.7 |— |67.3 |76.4 |— |\n|DeepseekCoder-6.7B |38.2 |49.5 |56.0 |55.6 |65.1 |69.0 |\n|DeepseekCoder-6.7B-SFT |48.8 |56.3 |59.7 |56.0 |64.4 |67.4 |\n|Deepseek-R1-Distill-Qwen-7B |— |— |— |— |— |— |\n|Deepseek-R1-Distill-Qwen-14B |— |— |— |— |— |— |\n|Deepseek-R1-Distill-Llama-8B |— |— |— |— |— |— |\n|Llama2-7B【图】 |— |— |— |— |— |— |\n|Llama3-8B【图】 |— |— |— |— |— |— |\n|CodeLlama-7B【图】 |— |— |— |— |— |— |\n|CodeLlama-34B【图】 |— |— |— |— |— |— |\n\n## 5. 进阶技巧与注意事项\n\n经过几周的实践，我们总结出一些能显著提升效率的技巧：\n\n\n1. **任务批量运行**：通过逗号分隔任务名可以一次评估多个任务，例如`--tasks humaneval,mbpp,multipl-e-python`\n2. **结果缓存机制**：相同参数的评估会自动缓存，通过`--overwrite_cache`强制刷新\n3. **自定义任务扩展**：在`tasks`目录下添加 YAML 配置文件即可扩展新任务，参考现有任务格式\n4. **分布式优化**：当 GPU 数量超过 4 时，设置`--parallelism 10`能更好地利用带宽\n\n安全方面需要特别注意：即使使用 Docker 隔离，也应避免在评估中使用生产环境的 GPU 集群，因为生成的代码可能包含恶意操作。框架虽然做了基本防护，但无法覆盖所有攻击向量。\n\n性能调优上，我们发现 batch_size 与 GPU 内存的关系并非线性，对于 A100-80G，设置 batch_size=8 时能达到最佳性价比。而对于 MultiPL-E 这种多语言任务，由于不同语言的 token 长度差异大，动态调整 max_length 能节省 20% 以上的计算时间。虽然我用的是实验室的NVIDIA 3090（也要几千多块钱一张了，但是显存多内存大），但是还是完成了任务的，这个毕竟只是学习用，不可能用上他们正在用的A800。。。\n\n## 6. 总结与展望\n\n第一次用 BigCode Harness 完整走完微调 - 评估流程，最大的感受是这个框架真正实现了 \"一次配置，多任务复用\" 的 promise。相比我们之前零散的评测脚本，标准化评估不仅节省了 70% 的工程时间，更重要的是让不同模型的对比结果有了信服力。\n\n在海南三月的暖阳里，看着实验数据一点点积累，从最初对参数调优的手足无措，到后来能熟练解读 pass@k 曲线背后的模型行为，这个过程还是比较好的。"
    },
    {
        "id": 2,
        "title": "GraphLAMA复现工作",
        "date": "2025-10-01",
        "author": "Busheng Zhang",
        "content": "# 在3090上复现GraphLAMA的踩坑与优化\n\n最近主播在学着做实验室图语言模型（GLM）的时候，读到了一篇非常亮眼的工作——[GraphLAMA](https://arxiv.org/abs/2405.18439)。它巧妙地解决了当前图语言模型在\"低资源场景\"下适配难的问题，效果拔群，主播立马有了\"复现一下\"的想法。\n\n然而，主播看到原论文的实验环境（3块A800）时，再看看主播现在能用的...3090，不禁倒吸一口凉气。这篇博客，主播想和大家分享一下如何从理解 GraphLAMA 的原理，到最终在有限的硬件资源上成功跑通它的全过程。\n\n如果你也对 GraphLAMA 感兴趣，或者正在为如何训练大模型而烦恼，希望主播的经验能给你带来一些启发。\n\n最终，主播把整个复现和适配的代码都开源了，欢迎大家 star 和交流：[https://github.com/gdshjzm/GraphLAMA\\_ggl](https://github.com/gdshjzm/GraphLAMA_ggl)，这是北邮GAMMALAB的一个实验项目，网址在[这里](https://github.com/BUPT_GAMMA/GraphLAMA_ggl)\n\n## GraphLAMA 原理趣谈：它解决了什么\"痛点\"？\n\n在深入实践之前，我们先花点时间聊聊 GraphLAMA 到底有多酷。\n\n目前的图语言模型（GLMs）主要有两种玩法：\n\n1. **上下文学习**: 就像开卷考试，你把几个例子（包含图结构和文本）一股脑塞进提示词里，让大模型（LLM）照着学。缺点很明显：性能一般，而且例子一多，上下文窗口就爆了，推理又慢又贵\n2. **指令微调**: 这就像是题海战术，用海量的标注数据去微调整个模型。效果是好，但标注数据的成本太高，在现实世界的很多场景里根本不现实\n\nGraphLAMA 则提供了一种\"中庸之道\"。它的核心思想是：**我只用极少量的数据，对模型里一小部分\"图专属\"的参数进行微调，既能达到好效果，又省钱省力。**\n\n这个过程分为\"预训练-适应-推理\"三步曲。\n\n它的框架里有几个很有意思的设计：\n\n  * **图编码器 (GNN)**: 先用一个图神经网络（比如 GAT）把图的结构信息提取成特征向量 (embedding)。\n  * **跳数编码 (Hop Encoding)**: 为了让模型知道节点离目标节点有多远，它给不同\"跳数\"（距离）的邻居加上了位置编码，这能更好地保留子图结构信息。  \n  * **双门控机制 (Gating Mechanism)**: 这是我觉得最巧妙的地方。它设计了两个\"门\"—— **任务相关门 (Task-Related Gate)** 和 **任务无关门 (Task-Invariant Gate)**。前者根据你的具体任务（比如节点分类）来筛选有用的特征；后者则保留那些通用的、与任务无关的图结构特征。\n  * **投影器 (Projector)**: 最后，通过一个简单的线性层，把处理好的图特征\"翻译\"成 LLM 能听懂的语言（token），然后和文本信息一起喂给 LLM。\n\n`在\"适应\"阶段，GraphLAMA 会冻结掉庞大的 LLM 和 GNN 主体，只去微调跳数编码、任务相关门等极少数参数。这使得整个微调过程的参数量极小，仅为 7B LLM 的万分之一，适配一个任务只需要 3MB 存储！\n\n## 复现之旅：直面 7B 模型的显存挑战\n\n理论搞清楚了，接下来就是动手环节。这也是整个过程中最\"酸爽\"的部分。\n\n### 硬件鸿沟与显存\"拦路虎\"\n\n原论文用的是 NVIDIA A800，而我这边主要是实验室的 NVIDIA 3090。一个 7B 的模型（Vicuna-7B），即使用半精度（FP16）加载，也需要大约 14GB 显存。但这仅仅是模型权重的静态占用。\n\n在训练过程中，显存的消耗大头还包括：\n\n  * **梯度 (Gradients)**: 每个需要训练的参数都会产生一个梯度，FP16 下也需要 14GB。\n  * **优化器状态 (Optimizer State)**: 如果使用 Adam 这样的优化器，它会为每个参数保存动量和方差，这部分的显存消耗是参数量的两倍，也就是 28GB。\n\n三者相加，FP16 训练至少需要 `14 + 14 + 28 = 56GB` 的显存。这对于单张 24GB 的 3090 来说，简直是天方夜谭。\n\n### 我的显存优化\"组合拳\"\n\n面对这个不可能完成的任务，我祭出了一套\"极限优化\"的组合拳，核心武器就是 **DeepSpeed ZeRO-3**。\n\n1.  **精度转换 (FP16)**: 这是最基础的一步，直接将模型从 FP32 切换到 FP16，所有显存占用减半。\n2.  **CPU Offload (CPU 卸载)**: 这是 DeepSpeed ZeRO-3 的精髓。它允许你将不立即参与计算的参数、梯度和优化器状态从 GPU 显存中\"卸载\"到内存（CPU）里，在需要时再加载回来。\n3.  **梯度累积 (Gradient Accumulation)**: 通过累积多个小批次的梯度，然后一次性更新模型。这相当于用时间换空间，可以显著降低单次迭代的显存峰值。\n4.  **分布式训练**: 我最终使用了两块 3090 进行分布式训练，进一步分摊了显存压力，也加速了训练进程。\n\n我尝试了两种不同的 DeepSpeed 配置方案：\n\n  * **方案一：极致优化**。将优化器和梯度全部卸载到 CPU。这种配置下，单卡显存占用可以被压到惊人的 7GB 左右。但缺点是 CPU 和 GPU 之间的数据交换会非常频繁，导致训练速度很慢，预计第一阶段要花 13-14 天。\n  * **方案二：均衡优化**。只将优化器状态卸载到 CPU，梯度依然保留在 GPU 中。这种方案下单卡显存占用在 19-20GB 左右，正好在 3090 的承受范围内，而且速度快得多，预计 3-4 天就能完成。\n\n最终主播选择了**方案二**，这样时间耗得也不算久，内存也不算多，deepspeed还是挺强大。\n\n### 代码适配：从 PyG 到 GammaGL\n\n原项目的代码实现依赖 PyTorch Geometric (PyG)。为了更好地与实验室的技术栈对齐，主播进行了一项额外的改造工作：将所有的 PyG 代码替换为他们自行研发的**GammaGL**框架。\n\n幸运的是，这两个框架的 API 接口高度相似，整个迁移过程比预想的要顺利。主要的不同点在于图对象的定义（PyG 的 `Data` vs GammaGL 的 `Graph`）和一些设备指定的方法上，但都很快解决了。\n\n## 训练启动与未来展望\n\n经过一番折腾，环境配置完毕，数据下载就绪，优化脚本也写好了。主播满怀期待地敲下了运行命令，看着日志滚动，GPU 占用率稳定在了 18642MB 左右，没有再报出可恶的 `CUDA out of memory`。那一刻，成就感满满！\n\n目前，模型正在服务器上稳定地进行第一阶段的预训练。虽然最终的测试结果还需要几天时间才能出炉，但能够成功地在消费级显卡上驯服 7B 规模的图语言模型，本身就是一次巨大的成功。\n\n再次附上我的项目地址，希望这份工作能帮助到社区里更多对 GLM 感兴趣的朋友们：\n**[https://github.com/gdshjzm/GraphLAMA\\_ggl](https://github.com/gdshjzm/GraphLAMA_ggl)**\n\n感谢阅读，最后记得给主播一个赞和关注哦～各位家人们，实时分享优秀论文和技术栈，也欢迎在评论区交流讨论。"
    },
    {
        "id": 3,
        "title": "Winter hack Challenge for QMUL",
        "date": "2025-10-18",
        "author": "Busheng Zhang",
        "content": "# Robot Path Exploration Optimization(For Winterhack London)\n\n## Submission necessary files:\nView for [github_repo](https://github.com/gdshjzm/Robot-Navig-for-Winterhack)\n```\n- main.py        # reference code that initially exist in the directory\n- main_.py       # >> main SUBMISSION CODE \n- video_demo.mov # video preview for random-seed-8 and snake-5-walls (most difficult where main.py failed)\n- README_en.md   # Technical details about my submission\n```\n\n## Overview\n\nThis project implements an intelligent frontier selection strategy based on multi-criteria comprehensive scoring to optimize robot path exploration efficiency in unknown environments. Compared to traditional simple linear combination methods, my strategy demonstrates significant performance improvements in various test scenarios.\n\n## Frontier Selection Strategy Design\n\n### Core Idea\n\nMy frontier selection strategy is based on the following core ideas:\n1. **Multi-dimensional Evaluation**: Evaluate frontier points from multiple dimensions such as information gain, path efficiency, goal orientation, and exploration balance.\n2. **Dynamic Weight Adjustment**: Dynamically adjust the weights of each evaluation metric based on exploration progress.\n3. **Intelligent Redundancy Avoidance**: Avoid redundant exploration near already explored areas through cluster analysis.\n4. **Introduction of Randomness**: Add a small amount of randomness to avoid getting stuck in local optima.\n\n### Detailed Explanation of Evaluation Metrics\n\n#### 1. Information Gain\n```python\ndef calculate_information_gain(cell: Cell) -> float:\n    \"\"\"Calculates the potential information gain of a frontier point\"\"\"\n```\n- **Principle**: Assesses the density of unknown areas around a frontier point.\n- **Calculation Method**: Counts the number of unknown cells within a certain range around the frontier point.\n- **Significance**: Prioritizes frontier points that can yield more new information.\n\n#### 2. Heading Alignment\n```python\ndef calculate_heading_alignment(cell: Cell) -> float:\n    \"\"\"Calculates alignment with the robot's heading\"\"\"\n```\n- **Principle**: Calculates the cosine similarity between the frontier point's direction and the robot's current heading.\n- **Calculation Method**: Uses vector dot product to determine alignment.\n- **Significance**: Reduces unnecessary turns and improves movement efficiency.\n\n#### 3. Goal Progress\n```python\ndef calculate_goal_progress(cell: Cell) -> float:\n    \"\"\"Calculates progress towards the goal\"\"\"\n```\n- **Principle**: Evaluates whether selecting this frontier point brings the robot closer to the final goal.\n- **Calculation Method**: Compares the distance from the robot's current position to the goal with the distance from the frontier point to the goal.\n- **Significance**: Maintains goal-oriented behavior during exploration.\n\n#### 4. Exploration Efficiency\n```python\ndef calculate_exploration_efficiency(cell: Cell) -> float:\n    \"\"\"Calculates exploration efficiency: distance from explored areas\"\"\"\n```\n- **Principle**: Encourages exploring frontier points far from already known areas.\n- **Calculation Method**: Calculates the distance from the frontier point to the nearest explored point.\n- **Significance**: Avoids redundant exploration near already explored regions.\n\n#### 5. Cluster Size\n```python\ndef calculate_cluster_size(cell: Cell) -> float:\n    \"\"\"Calculates the size of the cluster the frontier point belongs to\"\"\"\n```\n- **Principle**: Prioritizes frontier points within larger clusters.\n- **Calculation Method**: Uses a BFS algorithm to calculate the size of the cluster of adjacent frontier points.\n- **Significance**: Selects frontier points that allow for exploring larger areas at once.\n\n### Dynamic Weight Adjustment Mechanism\n\nMy strategy dynamically adjusts the weights of each metric based on exploration progress:\n\n```python\n# Early exploration phase: emphasize information gain and exploration efficiency\n# Later phase: emphasize goal orientation and heading alignment\nw_info = 0.3 * (1 - exploration_progress) + 0.1 * exploration_progress\nw_heading = 0.2 * (1 - exploration_progress) + 0.3 * exploration_progress  \nw_goal = 0.1 * (1 - exploration_progress) + 0.4 * exploration_progress\nw_efficiency = 0.2\nw_cluster = 0.1\n```\n\n**Design Philosophy**:\n- **Early Exploration**: Prioritize information gain and exploration efficiency to quickly build an environmental map.\n- **Later Exploration**: Focus more on goal orientation, moving directly towards the target.\n\n### Comprehensive Scoring Formula\n\nThe final frontier point score is calculated using the formula:\n\n```python\nscore = (w_info * info_gain + \n         w_heading * heading_align + \n         w_goal * goal_progress + \n         w_efficiency * exploration_eff + \n         w_cluster * cluster_size + \n         w_distance * distance_factor) + \n         0.01 * random_factor\n```\n\n## Comparison with Traditional Methods\n\nCompared to main.py, I used a more complex but stronger robustness method, which can display a better performance on complicated scenario than the reference code provided in main.py.\n\n### My Improved Method (main_.py)\n1. **Multi-dimensional Evaluation**: Added metrics such as information gain, exploration efficiency, and cluster analysis.\n2. **Dynamic Adaptability**: Adjusts strategy focus based on exploration progress.\n3. **Intelligent Redundancy Avoidance**: Prevents repetitive exploration through distance and cluster analysis.\n4. **Enhanced Robustness**: Adds randomness to avoid local optima.\n\n## Experimental Results Analysis\n\nI have tested our strategy performs excellently in multiple test scenarios:\n\n| Test Scenario | main_.py (My Method) | main.py (Reference Code) | Improvement |\n|---------------|-----------------------|------------------------------|-------------|\n| snake_5wall   | 5.206m                | 4.823m                       | -7.9%       |\n| random_seed0  | 2.230m                | 2.230m                       | No change   |\n| random_seed1  | 2.550m                | ERROR                        | **Error** |\n| random_seed2  | 2.395m                | 2.254m                       | -6.3%       |\n| random_seed24 | 2.473m                | 2.553m                       | **+3.1%**   |\n| random_seed15 | 2.983m                | ERROR                        | **Error** |\n| random_seed10 | 1.970m                | 1.998m                       | **+1.4%**   |\n| random_seed8  | 4.024m                | INF_LOOP                     | **Infinite Loop** |\n| random_seed55 | 2.800m                | 2.371m                       | -18.1%      |\n\n### Key Advantages\n\n1. **Significantly Improved Robustness**:\n   - Resolved errors in `random_seed1` and `random_seed15` that occurred with the traditional method.\n   - Fixed the infinite loop issue in `random_seed8`.\n\n2. **Stable Performance**:\n   - Maintained competitive path lengths in most test scenarios.\n   - Achieved path optimization in `random_seed24` and `random_seed10`.\n\n3. **Strong Adaptability**:\n   - Capable of handling various complex maze environments.\n   - Operates stably across different random seeds.\n\n### Performance Analysis\n\nWhile my method's path length is slightly longer in some scenarios (e.g., `snake_5wall` and `random_seed55`), this is a reasonable trade-off for better robustness and stability:\n\n1. **More Conservative Exploration Strategy**: Avoids aggressive choices that could lead to errors or infinite loops.\n2. **More Thorough Information Gathering**: Emphasizes information gain in early stages, potentially leading to slightly longer but safer paths.\n3. **Smarter Goal Orientation**: Goal-oriented behavior in later stages ensures successful arrival at the target.\n\n## Technical Features\n\n### 1. Computational Efficiency Optimization\n- Limited cluster search range to avoid excessive computation.\n- Utilized caching mechanisms to reduce redundant calculations.\n- Implemented reasonable search depth control.\n\n### 2. Parameter Tunability\n- All weight parameters can be adjusted according to specific application scenarios.\n- Supports different exploration strategy configurations.\n- Easy to extend with new evaluation metrics.\n\n### 3. Code Maintainability\n- Modular function design.\n- Clear comments and documentation.\n- Easy-to-understand algorithm logic.\n\n## Conclusion\n\nOur intelligent frontier selection strategy significantly enhances the robustness and efficiency of robot path exploration through multi-dimensional evaluation, dynamic weight adjustment, and intelligent redundancy avoidance. Experimental results demonstrate that this strategy can:\n\n1. **Address stability issues of traditional methods**: Eliminating errors and infinite loops.\n2. **Maintain competitive path efficiency**: Achieving comparable or superior path lengths in most scenarios.\n3. **Provide better adaptability**: Capable of handling various complex environments and random scenarios.\n\nThis design, balancing efficiency, robustness, and adaptability, makes our strategy more suitable for practical robot navigation applications.\n\n## !!Important: AI Usage Details\n**Declaration:I write this details to make AI usage more transparent and make every code I wrote believable.**\n1. Code: All code is written by myself using AI Tab completion.\n    - heading alignment and goal progress function are taken reference code main.py.\n    - Information gain and dynamic weight are new ideas by me and I wrote the raw code manually.\n    - Used AI to add a total distance demonstration so that I can compare different methods.\n    - Testing raw code occured many bugs and I used AI to debug (only on code issues like value errors, without using new method beyond).\n    After all code completed, I used Calude-4-Sonnet to handle with tranceback errors.\n2. README tech file: Almost written by AI and was manually modified to ensure readability.\n3. video: Shot full-manually without AI."
    },
    {
        "id": 4,
        "title": "【论文精读】·GFM经典论文",
        "date": "2025-10-23",
        "author": "Busheng Zhang",
        "content": "\t之前因为一些事情很久没有更新我的文档了，今天我重新鼓起勇气更新最近读的一些论文，感触还是非常深的。今天主播就来梳理一下经典的图预言模型吧。\n\n# 1. GOFA-Generative One-For-All Framework\n这篇文章是来2025年4月份发的论文，虽然这篇论文的star数量不高，引用量也很少，但是通过这篇文章，主播也收获了良多，包括论文阅读的习惯，以及将图数据嵌入大语言模型的一些策略。\n\n这篇文章提出了一种名为 GOFA (Generative One-for-All) 的新型生成式图语言模型。该模型旨在解决现有图基础模型 (GFM) 无法同时兼顾图结构理解和任务灵活性的挑战。GOFA 的核心方法是将随机初始化的 GNN（图神经网络）层交错插入到一个冻结的、预训练的 LLM（大语言模型）中，从而有机地结合 LLM 的语义建模能力和 GNN 的结构建模能力。\n## 1.1 什么是Graph Foundation Model？\n开发一个通用的图基础模型 (GFM) 极具挑战性，因为图数据不像文本或图像那样具有固定的结构 。当前构建通用图模型的尝试主要分为两条路径，但各有缺陷：\n1. **LLM 作为预测器 (LLM as a predictor)**：这类方法将图数据转换为 LLM 能够理解的语言格式 ，然后利用 LLM 进行预测 。虽然这种方法理论上可以处理无限的任务 ，但近期研究指出它们在理解图结构方面表现不佳 。\n2. **LLM 作为增强器 (LLM as an enhancer)**：这类方法使用 LLM 来处理和统一不同图数据的特征 ，然后将这些特征输入 GNN 进行训练 。这种方法能更好地捕捉图结构 ，但其 GNN 的输出是固定大小的表示或预测 ，导致模型只能处理分类等特定任务 ，缺乏生成任意新任务的能力 。\n综上所述，现有的方法无法同时做到充分利用结构信息并具备（像 LLM 一样的）生成能力 。\n\n因此，本文作者首先确定了一个理想的 GFM 应具备的三个关键特性：\n- **大规模自监督预训练** ：能够在多样化、无标签的大规模图数据上进行训练 。\n- **任务的流动性** (Fluidity in tasks) ：能像 LLM 一样灵活处理不同的图任务，甚至是在上下文中学习新任务 。\n- **图理解能力** (Graph understanding) ：能解释图的独特结构信息（如节点度、最短路径等），并根据输入提示联合学习图结构和语义信息 。\n\nGOFA 模型的设计目标就是为了同时满足这三个特性 。\n## 1.2 架构\nGOFA 的方法论主要包括统一的任务格式、图生成建模框架以及 GNN-LLM 交错的架构。\n\n为了处理来自不同领域、具有不同特征的图数据，GOFA 采用了文本属性图 (TAG) 作为统一的输入表示。\n\n- **定义**：TAG 是一个图 $G=\\{V,E,X_{V},X_{E}\\}$ ，其中每个节点 $v$ 和每条边 $e$ 都对应一个文本描述 $x(v) \\in X_{V}$ (或 $x(e) \\in X_{E}$) 。\n- **泛化**：任何图特征都可以被转换为文本。例如，数值特征可以转换为文本字符串，即使是没有特征的图，也可以附加“该节点的度为 3”这样的句子。这种格式几乎可以编码所有现有的图数据。\n\nGOFA 将所有图任务统一为“图补全”任务。\n\n- **NOG**：模型引入了“生成节点 (Nodes of Generation, NOG)”，允许用户指定图中的哪些节点是生成文本的起点。\n- **目标**：该框架的目标是建模在给定图 $G$ 和 NOG 节点 $v$ 的条件下，生成与 NOG 相关的文本 $y$ 的似然。\n- 公式：$$p(y|v,G)=\\prod_{l=1}^{L}p(y_{l}|y_{<l},v,G),$$\n其中 $y_{l}$ 是 $y$ 的第 l 个 token。\n\n为了解决上述建模问题，GOFA 设计了一个由图语言编码器 (Graph Language Encoder) 和 LLM 解码器 (LLM Decoder) 组成的架构。\n- **图语言编码器**：\n    1. **LLM 压缩器 (LLM compressor)**：传统的 GNN 需要固定维度的节点表示，但将 LLM 的 token 池化 (pooling) 会丢失语义信息。因此，GOFA 采用了一个预训练的句子压缩器（受 ICAE启发），该压缩器可以将一个句子（即节点或边的文本）压缩为 $K$ 个固定大小的多 token 嵌入，称为 Memory Token。\n    2. **GNN-LLM 交错设计**：这是 GOFA 的核心。它将 GNN 层与 LLM 压缩器层交错排布。\n    3. **流程**：在第 $t$ 层，来自前一个 GNN 层的 Memory Tokens 输出 $H_{x}^{t}$ 与原始文本 tokens $Q_{x}^{t}$ 相拼接，一同输入到 LLM 压缩器层 $LLM^{t}$。\n    4. $LLM^{t}$ 的输出 $Q_{m,x}^{t+1}$（对应 Memory Tokens 的部分）接着被送入 Token 级的 GNN 层。\n    5. Token 级 GNN：GNN 层在 $K$ 个 Memory Tokens 的每个索引 $k$ 上独立进行消息传递。$$H_{x(v)}^{t}[k]=GNN(Q_{m,x(v)}^{t}[k],\\{(Q_{m,x(u)}^{t}[k],Q_{m,x(e_{uv})}^{t}[k])|u\\in\\mathcal{N}(v)\\}), k=1...K.$$\n    6. 虽然 GNN 层内的 token 是隔离的，但它们在随后的 LLM 压缩器层的自注意力机制中会交换信息。\n- **LLM 解码器**：\n    - 经过编码器处理后，NOG 节点 $v$ 的 Memory Tokens $Q_{m,x}$ 已经融合了其自身的文本信息、周围节点的文本信息以及图结构信息。\n    - 这些 $Q_{m,x}$ 被插入到目标文本 $y$ 的 token 嵌入之前，然后使用标准的 Teacher-Forcing 和下一词预测目标来训练 LLM 解码器。\n\n所有任务（节点级、链接级、图级）都被转换为在目标节点周围提取的 k-hop 子图上的任务。一个带有用户查询的“提示节点 (prompt node)”作为 NOG，连接到所有目标节点。GOFA 通过在 NOG 上回答查询来完成 TAG。\n\n![GOFA架构图](img/截屏2025-10-23 19.54.24.png)\n## 1.3 实验\n实验设计旨在回答四个核心研究问题 (RQ)：\n- **Q1**: GOFA 的预训练任务对图语言建模和结构理解是否有效？\n- **Q2**: 预训练的 GOFA 是否有助于关键的零样本学习应用？\n- **Q3**: 在图任务上使用 GOFA 是否比使用 LLM 更有优势？\n- **Q4**: GOFA 是否具有处理开放式图相关任务的流动性？\n\n|**模型**|**Perplexity ↓**|**SPD (RMSE) ↓**|**CN (RMSE) ↓**|\n|---|---|---|---|\n|Mistral-7B|30.12 84|1.254 85|1.035 86|\n|GOFA-SN (无连接)|26.20 87|N/A|N/A|\n|GOFA|21.34 88|0.634 89|0.326 90|\n![GOFA实验结果](img/截屏2025-10-23 20.06.56.png)\n## 1.4 结论\nGOFA 在大多数数据集上（如 Cora-Node, WikiCS, Products, FB15K237, ExplaGraphs）的表现优于 LLM 和现有的图基础模型基线（如 OFA, UniGraph, LLaGA） 。在 WikiCS, Products, FB15K237 和 ExplaGraphs 数据集上，GOFA 甚至超过了最佳基线 10% 以上 。这证明了 GOFA 结合 LLM 和 GNN 优势的强大泛化能力。\n# 2. LLaGA-Large Language and Graph Assistant\n这篇论文相对来说非常经典，是来自2024年的工作，Github星星数也非常高，在各类数据集上面显示出较好的效果。\n\n## 2.1 为什么要做这篇工作？\n在构建模型的时候，GNN 多任务能力弱，需任务特定头或微调；LLM 处理图数据时，转自然语言易丢失结构信息，微调方案又牺牲通用性；GraphGPT 的预训练图 Transformer 可能丢失关键信息。为此需构建能兼顾图结构编码与 LLM 通用性的框架。\n\n这篇工作可以属于前一篇的LLM as a predictor类别，更像是图给大语言模型的一种「喂法」，偏向于在保证大语言模型能力不受影响的基础上，让大语言模型理解图的结构和信息。\n## 2.2 架构\n这是论文的架构图：\n![[截屏2025-10-23 20.28.32.png]]主播为了加深理解，也做了一个详细版的架构图：\n![[c9b788b5fcd1e1e68b5cd15f51260f84.jpg]]\nLLaGA 通过 “图结构转换→节点嵌入映射→对齐训练” 三步流程，实现 LLM 与图数据的无缝整合，核心包含**符号定义、结构感知图转换、通用投影仪（Projector）、对齐训练**四大模块，整体设计聚焦 “无参数结构保留” 与 “低成本 LLM 适配”。\n### Neighborhood Detail Template\n1. 以目标节点为根，构建固定形状的 “计算树”：对每跳邻域设定采样数量\\(n_1,n_2,...\\)（如 2 跳邻域每跳采样 10 个节点），从k跳邻域\\(N_v^k\\)中随机采样\\(n_k\\)个节点，若邻域节点数不足，则用占位符（\\[pad\\]）补全至\\(n_k\\)个；\n2. 对计算树进行**层序遍历**（从根节点到子节点按层依次遍历），生成固定长度的节点序列（例如节点 A 的 2 跳序列为\\(A B C D A G \\[pad\\] A \\[pad\\] \\[pad\\] A\\)），序列中每个位置对应图中唯一的结构位置，确保结构信息不丢失。\n### HopField Overview Template\n1. 通过**无参数消息传递**计算节点的 “跳嵌入（hop embedding）”：初始嵌入\\(h_v^0=\\phi(x_v)\\)（\\(\\phi\\)为文本编码器，如 SBERT、RoBERTa），第i跳嵌入\\(h_v^i\\)整合第i跳邻域所有节点的信息；\n2. 以跳嵌入序列\\(h_v^0,h_v^1,h_v^2,...\\)（如 4 跳嵌入）作为节点序列，用单个嵌入概括每跳邻域的整体特征，牺牲部分细节以换取更大的邻域感受野。\n### 对齐操作\n将上述 「节点序列的嵌入」（含节点文本特征 + 图结构信息）使用一个简单的MLP投影器映射到 LLM 的 Token 嵌入空间，避免直接微调 LLM 参数（大幅降低计算成本），同时确保 LLM 能理解图信息。\n## 1.3 实验部分\n### 实验基本问题\n实验选用 4 个跨领域图数据集（Cora、Pubmed、ogbn-Arxiv 引文网络与 ogbn-Products 电商网络），覆盖不同规模与稀疏度；聚焦节点分类、链路预测、节点描述 3 类核心任务，分别以准确率、SBERT 相似度等为评价指标；对比 4 类基线模型（GNN 类如 GCN、Transformer 图模型如 NodeFormer、LLM 类如 GPT-3.5、并发工作 GraphGPT），核心配置为基础 LLM（Vicuna-7B-v1.5-16K）、文本编码器（默认 SimTeG），并构建 LLaGA-ND-7B（邻域细节模板）与 LLaGA-HO-7B（跳域概览模板）两种模型。\n### 实验结果\nLLaGA 在 Single Focus、Task Expert 等 4 种设置下均显著优于所有基线，且多任务场景性能下降少（如 General Model 设置下 ogbn-Arxiv 节点分类准确率 75.01%，远超 GPT-3.5 的 55.00%）；零样本泛化能力突出，域内（引文网络间）与跨域（引文→电商）迁移准确率均超基线（如跨域链路预测准确率 92.99%，是 GCN 的 1.6 倍）；消融实验证明两种模板对结构信息编码至关重要，无模板模型性能明显更低；节点描述任务中，SBERT 相似度高且描述标签准确率优（如 Pubmed 达 94.27%），可解释性强。\n\n## 个人感悟\n不论是从LLaGA的LLM图喂法，还是GOFA的网络串行，其中核心的要点是如何将图的结构和特征信息表征到一个嵌入中，这是最核心的一点，我们在阅读其他类型的工作也会遇到这类同样的问题，同时，这也一定是LLM突破「语言」这一单一模态的「核心要义」。\n\n\n感谢阅读，最后记得给主播一个赞和关注哦～各位家人们，实时分享优秀论文和技术栈，也欢迎在评论区交流讨论～～"
    },
    {
        "id": 5,
        "title": "数学建模25C",
        "date": "2025-09-11",
        "author": "Busheng Zhang",
        "content": "\n2025 年 9 月，主播和团队成员第一次拿到「高教社杯」全国大学生竞赛的题目时，临床案例里那句 “高 BMI 孕妇因检测时机不当错过最佳干预窗口” 的描述，瞬间让我们意识到这不是一道单纯的数学题 —— 我们要做的，是能真正落地临床、减少医患遗憾的解决方案。接下来的三天，从数据清洗到模型迭代，从无数次失败到最终提交，每一步都刻满了团队的心血。\n\n## 一、初遇数据集：在 “混乱” 中搭建分析框架\n\n竞赛题目提供的 1082 条 NIPT 数据，初看时像一团乱麻：BMI 缺失值散落在不同字段，孕周记录格式五花八门（“13w+4d”“91 天”“13 周” 并存），同一孕妇单次抽血的 3 次重复检测数据混在其中，更棘手的是 GC 含量异常的样本占比高达 47.97%。如果不先理清这些 “乱象”，后续建模只会 “差之毫厘，谬以千里”。\n![数据分析截图](img/截屏2025-10-23 22.32.03.png)\n团队第一步就扎进了数据预处理。针对 BMI 缺失，我们从原始数据中提取身高、体重，用 BMI = 体重 (kg)/ 身高 (m)² 重新计算填补；末次月经缺失的 5 例样本因占比过低，为避免偏差直接剔除。为统一时间尺度，主播写了正则表达式脚本，将所有 “周 + 天” 格式转换成总天数，比如 “23w+4d” 换算成 165 天，确保建模时时间维度的一致性。\n\n最耗时的是数据聚合与质量控制。同一孕妇同次抽血的多次检测属于重复测量，我们按 “孕妇代码 + 检测抽血次数” 分组，对 BMI、孕周等指标取均值，避免数据权重失衡；针对 GC 含量，参考临床共识设定总 GC 含量正常范围为 \\[40%,60%\\]，又通过计算 13 号、18 号、21 号染色体 GC 含量的 5% 和 95% 分位数，确定各染色体的特异性阈值，将所有超标样本标记为低质量，后续建模时降低其权重。\n\n那段时间，团队每天对着 Python 可视化图表反复核对 —— 当看到 85% 的孕妇集中在 25-34 岁，检测孕周主要分布在 17.5-22.5 周时，我们才松了口气：这些数据既符合临床实际，又有足够的个体差异可供挖掘，为后续建模打下了坚实基础。\n\n## 二、问题一攻坚：用混合效应模型打破 “虚假无关”\n\n竞赛第一题要求分析 BMI、孕周与胎儿 Y 染色体浓度的相关性，起初主播信心满满地用皮尔逊相关系数计算，结果却令人沮丧 —— 整体相关性系数最高仅 - 0.164，多数指标与 Y 染色体浓度的关联微弱，甚至看不出明显趋势。难道这些生理指标真的无关紧要？\n\n就在大家陷入迷茫时，主播突然想到：“同一孕妇有多次检测数据，这是嵌套结构，不能当独立样本处理。” 这句话点醒了我们。原来，孕妇个体差异（如基础代谢、胎盘功能）掩盖了群体层面的相关性。主播决定改用混合效应模型，将 “群体平均趋势”（固定效应）和 “个体差异”（随机效应）分开建模，看到可视化图表，这才释然。\n![[截屏2025-10-23 22.33.07.png]]\n为消除 BMI 和孕周的拮抗关系，我们构建新指标 cfEB=Y 染色体浓度 / BMI×1000，再对 BMI 和孕周做中心化处理，让截距项更具临床意义。建模过程中，我们尝试了 “仅随机截距”“随机截距 + 随机斜率” 等多种结构，最终通过似然比检验（LRT）发现，纳入孕周随机斜率的模型拟合效果显著更优 —— 条件 R² 从 0.141 飙升至 0.726，意味着模型能解释 72.6% 的变异，而之前的普通回归仅能解释 14.1%。\n![[截屏2025-10-23 22.33.48.png]]\n当 Wald 检验结果显示：孕周对 Y 染色体浓度是显著正向影响（z=13.218，p<0.001），BMI 是显著负向影响（z=-2.563，p=0.010）时，主播和其他的小伙伴们都兴奋地击掌 —— 这个结果不仅符合医学常识（孕周越大胎盘发育越成熟，胎儿游离 DNA 越多；高 BMI 会稀释胎儿 DNA），更证明了个体差异的重要性，为后续个性化检测方案提供了理论依据。\n\n## 三、问题二突破：AFT 模型与决策树的 “双向奔赴”\n\n第二题要求按 BMI 分组并确定最佳检测时点，这面临两个核心难题：如何科学分组？如何处理 “删失数据”（如部分孕妇末次检测仍未达标，部分首次检测就达标）？\n\n主播和伙伴们先尝试 K-means 聚类，但 BMI 与 Y 染色体浓度的非线性关系让聚类结果混乱。后来想到，决策树能通过最小化信息熵自动找到最优分割点，还能结合临床意义调整。我们为每位孕妇构建线性回归，提取基线 Y 浓度（β₀）、孕周效应（β₁）、BMI 效应（β₂）作为特征，用 CART 回归树最终将 BMI 分成 4 组：\\[20.7,30.3\\]、\\[30.4,31.8\\]、\\[31.8,33.8\\]、\\[33.9,46.9\\]，每组的 β 系数特征一致性很高，让分组结果更具说服力。\n\n处理删失数据时，生存分析中的 AFT（加速时间失效模型）成了 “救星”。它能同时应对左删失、右删失和区间删失，还能输出时间概率分布，比普通回归更贴合 “达标时间” 的实际场景。我们用 Weibull 分布拟合 AFT 模型，提取 P50（中位数）、P90（90% 分位数）作为推荐时点 —— 考虑到临床对准确性的高要求，最终选择 P90 分位数，确保 90% 的孕妇在该时点检测能达标。\n![[截屏2025-10-23 22.36.43.png]]\n为验证模型稳健性，主播和伙伴们做了蒙特卡洛模拟，给 Y 浓度、孕周、达标阈值分别添加 7%、0.2 周、0.001 的随机扰动，结果各组推荐时点的变异系数（CV）都低于 0.03，波动仅 0.6-2.1 天，完全在临床可接受范围内。当看到不同 BMI 组的生存曲线清晰分离，高 BMI 组的推荐时点（17.4 周）比低 BMI 组（15.7 周）晚近 2 周时，我们真切感受到：数据驱动的个性化方案，比经验判断更精准。\n\n## 四、问题三升级：多因素与风险控制的 “双重保障”\n\n第三题要求加入年龄、身高、体重等多变量，这就需要先解决多重共线性问题 —— 比如身高和体重的相关系数达 0.619，直接入模会放大误差。伙伴们用方差膨胀因子（VIF）检验，发现所有变量的 VIF 都小于 2，说明多重共线性不影响模型结果，于是放心地将身高、体重、年龄、产次等纳入协变量矩阵。\n\n个体回归结果很有意思：年龄越大，Y 染色体浓度略低（γ_age 多为负）；经产妇比初产妇的胎儿游离 DNA 更多（γ_par 多为正），这与文献结论一致。但竞赛题目更强调风险控制 —— 医学决策不能只看 “平均情况”，还要防范极端风险。我们引入 CVaR（条件风险价值），量化 “未达标” 的尾部风险，确保推荐时点在最大可接受风险范围内。\n\n最终结果显示，BMI 越高，CVaR 值越大：BMI 最高组（33.4-46.9）的 95% CVaR 达 23.148 周，而最低组（20.7-29.8）仅 19.737 周。这意味着高 BMI 孕妇不仅达标时间晚，风险波动也更大，临床中需要更保守的检测策略 —— 比如推迟到 19 周后检测，同时加强随访。\n\n## 五、问题四博弈：与数据不平衡的 “殊死较量”\n\n第四题是女胎异常判定，典型的二分类问题，但异常样本仅占 6.2%，数据极度不平衡。如果直接建模，模型会偏向预测 “正常”，导致漏诊率飙升 —— 这在临床中是绝对不能接受的，也不符合对 “临床实用性” 的要求。\n![[截屏2025-10-23 22.38.18.png]]\n主播和伙伴们对比了 SMOTE 和低秩优化两种过采样方法。SMOTE 通过线性插值生成新样本，但容易产生 “越界数据”；而低秩优化能从全局结构中生成更符合真实分布的样本，类间距离从 43.337 提升到 68.977，分离效果更优。最终我们用低秩优化将异常样本比例提升至近 50%，再用代价敏感 XGBoost 建模 —— 通过设置更高的漏诊代价（CFN），强制模型关注异常样本。\n![[截屏2025-10-23 22.38.40.png]]\n模型评估时，我们重点看召回率（捕捉异常样本的能力），最终推荐阈值 0.038 对应的召回率达 0.85，ROC-AUC 为 0.684。特征重要性分析显示，cfEB、13 号染色体 GC 含量、BMI 是 Top3 影响因素，这与前几问的结论相互印证，也为临床医生提供了明确的风险指标。![[截屏2025-10-23 22.39.00.png]]\n\n## 六、竞赛落幕：从模型到临床的 “未完之路”\n\n2025 年 2 月，当团队将最终论文提交到「高教社杯」系统时，窗外已经泛起晨光。五个月里，我们推翻过 3 次建模思路，调试 AFT 模型参数到凌晨，为了一个数据异常值争论半天 —— 但当看到最终结果：不同 BMI 组的推荐检测时点能精准匹配临床风险，女胎异常判定模型的漏诊率控制在 15% 以下时，所有的辛苦都有了意义。\n\n这次竞赛让主播和团队深刻明白，数学建模不是 “炫技”，而是要扎根实际需求：混合效应模型的价值在于尊重个体差异，AFT 模型的优势在于贴合检测数据特性，风险控制的核心是为医生提供 “可信赖的决策依据”。未来，我们计划用多中心数据验证模型泛化性，让这份竞赛成果真正走进临床，不再让 “时机不当” 成为医患的遗憾。\n\n或许这份研究不是最完美的，但它承载着一群大学生对 “用数据解决临床痛点” 的初心 —— 而这，正是「高教社杯」教会我们的最重要的事。"
    }
]